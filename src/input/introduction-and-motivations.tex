%\subsection{Introduction and Motivations}\label{subsec:introduction-and-motivations} % bevezetés és motivációk
%értelmezés

\section{Introduction}\label{sec:introduction}

The accurate detection of objects that are relevant to vehicle control is a critical task in the field of automotive and transportation systems.
It is a particularly important aspect for the development of highly sophisticated autonomous driving systems, where numerous scenarios can arise with different types of objects to detect and react to.
These objects can be either static (not moving), or dynamic (capable of moving).
The object detection is implemented through the help of sensors using different physical phenomena, such as acoustic or electromagnetic waves.
These sensors are mounted to the chassis of the autonomous vehicle.

One of the most widely used solution is the use of camera sensors as they are able to
provide rich visual data that can be processed rapidly and can give the most information by itself.
The main goal of this project was to develop a software capable of detecting dynamic traffic
objects, while staying robust and reliable in various conditions.
A fitting solution for this task was to utilise deep learning models, especially Convolutional Neural Networks, CNNs for short.

%értelmezés
Nevertheless, the most significant limitation of these models is that they are frequently regarded as black boxes, lacking a straightforward correlation between input and output.
As we might want to use these systems in safety critical applications,
it is important to avoid unpredictable model-behaviour or mistrust from the stakeholders.
High level of explainability should be the bases for trust and confidence between the system and its stakeholders.
In accordance with this, the artificial intelligence-functional safety and AI systems ISO standard~\cite{ISO5469:2021} devotes a chapter (8.3) to
Degree of transparency and explainability.
These needs led to the development of numerous model interpretation techniques,
as evidenced by the work of a number of different researchers such as Yu Liang~\cite{LIANG2021168}.
These techniques vary in their approach, but they are all aiming to facilitate an insight into the decision-making process of the model.
In a unified manner, these methods are called eXplainable Artificial Intelligence methods, XAI for short.


%feladat indokoltsága
The complexity of interpreting models in these domains arises from two key factors: the intricate nature of the data and the sheer size of models used.
The aforementioned complexity makes it challenging to trace the decision-making process, which unfolds across numerous neurons and layers,
presents a significant challenge.
Ne-vertheless, it is essential for the identification of potential biases, the improvement of model performance, the fostering the trust of users and regulatory bodies.
These factors are particularly important in the context of traffic object detection, where the consequences of model errors can be severe.
This has heightened the importance of XAI solutions, with the aim of ensuring transparency for end users and developers alike.

As previously discussed in relation to other challenges facing the development of AI systems by Arun Das and Paul Rad in their article
\("\)Opportunities and Challenges in the Development of AI Systems\("\)~\cite{das2020opportunitieschallengesexplainableartificial}
the General Data Protection Regulation (GDPR) now requires that decisions made by automated systems be
explainable to the user.
Although the GDPR does not explicitly mention XAI and mainly focuses on data privacy,
it seems probable that in the future, there will be a greater expectation of algorithmic transparency and clarification of AI systems.

%tervezés célja
It is therefore essential to enhance the interpretability of this project's model through the use of the aforementioned
XAI methods such as SHAP, LIME and EigenCAM in order to maintain safety and ethical standards, given the nature of the
application.
Based on that the secondary objective of this project was to try and implement these interpretation methods and examine their
effectiveness in the context of traffic object detection and try to instate a more transparent and reliable model.

\subsection{Task refinement}\label{subsec:Refinement-of-the-task} % feladat finomítása

Based on the different types of tasks I wanted to accomplish, I decided to separate them into two different tasks.

The principal objective of this project is to develop a software solution capable of detecting traffic objects in real time.
This will entail an investigation into the fundamental principles of deep learning models for object detection, with a
par-ti-cu-lar emphasis on the construction of a model based on the YOLOv8 architectural framework.
The model will be trained on a dataset comprising images of urban en-vi-ron-ments, each of which has been annotated with
traffic objects.
Following training, the performance of the model will be evaluated based on its capacity to accurately detect traffic objects
in real scenarios.

In addition to object detection, the secondary objective of the project is to enhance the interpretability of the
model through the utilisation of Explainable AI (XAI) me\-tho\-do\-lo\-gies.
The selection and implementation of both model-agnostic and model-specific interpretation techniques will be undertaken (they will be discussed and explained later),
with a particular focus on understanding their underlying prin-cip-les and applying them to the traffic detection model.
The effectiveness of these interpretation techniques will be evaluated based on their
ability to provide insights into the rationale behind the model's predictions.
This will ensure that the system is accurate and transparent in its decision-making processes.
\newpage
The objective of this project is to develop a deep learning model for traffic object detection and to apply XAI methods to enhance the model's interpretability.

The two tasks were approached as discrete entities, and thus their explanations were presented separately.
Initially, the object detection and the neural network's fulfilment of the task and its evaluation were discussed.
Subsequently, the model's interpretation methods and their outcomes were evaluated.

The selection of dataset, model and interpretation methods was made with these goals in mind, with the intention of optimizing the model for the task in question, in line with the findings of the literature and previous studies.

\subsection{Structure}\label{subsec:Structure} % felépítés rövid összefoglalása

The main structure of my thesis is outlined as follows.

The first major section focuses on the object detection component, which is divided into several subsections.
It begins with a literature review on image processing techniques using deep convolutional neural networks.
Following this, I provide a detailed description of the YOLO architecture, including an overview of the training process and the infrastructure used.
Next, I cover data processing and representation with the Cityscapes dataset. I also give an overview of the training process. This section concludes with an evaluation of the model’s performance.

The second main section addresses interpretation methods.
It starts with an overview of model-agnostic and model-dependent interpretation techniques.
Then, I present the implementation, application, and evaluation of the EigenCAM, LIME, and SHAP methods.
Finally, this section analyses the results and draws conclusions regarding the effectiveness of the model interpretability solutions for detecting traffic objects.

\newpage